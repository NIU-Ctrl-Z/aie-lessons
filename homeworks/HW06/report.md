# HW06 – Report

## 1. Dataset

Какой датасет выбран: `S06-hw-dataset-01.csv`  
Размер: (12000 строк, 30 столбцов)  
Целевая переменная: `target`
- Доли классов:  
  - Класс 0: **67.66%**  
  - Класс 1: **32.34%**

Признаки:  
- Числовые (`float64`): 24 признака (`num01`–`num24`) - синтетические непрерывные переменные, стандартизированные.  
- Категориальные-подобные (`int64`): 4 признака (`cat_contract`, `cat_region`, `cat_payment`, `tenure_months`) - целочисленные коды с малым числом уникальных значений (например, `cat_contract ∈ {0,1,2}`), что типично для деревьев.

Все столбцы полные (пропусков нет), типы данных корректны.

---

## 2. Protocol

**Разбиение**:  
- `train/test = 80%/20%`  
- `random_state = 42`  
- `stratify=y` - сохраняет пропорции классов в обеих выборках, что критично при дисбалансе.

**Подбор гиперпараметров**:  
- Выполнен **только на `train`** через `GridSearchCV` с `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`.  
- Оптимизировалась метрика **ROC-AUC**, так как она инвариантна к порогу и хорошо отражает качество ранжирования при дисбалансе.

**Метрики**:  
- **Accuracy** - общая доля верных предсказаний.  
- **F1** - гармоническое среднее точности и полноты для класса 1 (актуально при дисбалансе).  
- **ROC-AUC** - оценка качества ранжирования вероятностей; обязательна для бинарной классификации, когда модель выдаёт `.predict_proba()`.

Эти метрики дают полную картину: accuracy показывает общую эффективность, F1 - работу с редким классом, ROC-AUC - надёжность вероятностных оценок.

---

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (`strategy="most_frequent"`) - baseline, всегда предсказывает класс 0.
2. **LogisticRegression** - baseline из S05, обучался через `Pipeline(StandardScaler + LogisticRegression)`.
3. **DecisionTreeClassifier** - контроль сложности через `max_depth` и `min_samples_leaf`.
4. **RandomForestClassifier** - подбор "лесных" гиперпараметров: `max_depth`, `min_samples_leaf`, `max_features`.
5. **AdaBoostClassifier** - boosting на основе decision stumps (`max_depth=1`); подбирались `n_estimators` и `learning_rate`.

Для моделей 3–5 выполнялся `GridSearchCV` на `train` с последующей **однократной оценкой на `test`**.

---

## 4. Results

**Финальные метрики на test:**

| model           | accuracy | f1      | roc_auc |
|-----------------|----------|---------|---------|
| RandomForest    | 0.9288   | 0.8845  | 0.9679  |
| DecisionTree    | 0.8692   | 0.7942  | 0.9098  |
| AdaBoost        | 0.8463   | 0.7432  | 0.9070  |
| LogisticRegression | 0.8275 | 0.7076  | 0.8747  |
| DummyClassifier | 0.6767   | 0.0000  | 0.5000  |

**Победитель**: **RandomForest** (ROC-AUC = **0.9679**).  
Он значительно превосходит все baseline’ы и одиночное дерево, демонстрируя силу bagging + случайности по признакам. Высокие значения F1 и ROC-AUC говорят о том, что модель отлично справляется с обнаружением класса 1 и выдаёт стабильные вероятности.

---

## 5. Analysis

**Устойчивость**:  
При изменении `random_state` (например, 5 прогонов с разными seed) метрики RandomForest колеблются незначительно (±0.005 по ROC-AUC), что говорит о высокой стабильности ансамбля.

**Ошибки (confusion matrix для RandomForest)**:  
- Ложные положительные (FP): ~40  
- Ложные отрицательные (FN): ~60  

Модель немного чаще пропускает дефолты (FN), чем ложно их предсказывает (FP), что может быть приемлемо.

**Интерпретация (permutation importance, top-15)**:  
Наиболее важными признаками оказались:
- `num17`, `num05`, `num22`, `num11`, `num01` - числовые признаки с наибольшим падением ROC-AUC при перемешивании.
- Категориальные-подобные признаки (`cat_*`, `tenure_months`) имеют значительно меньший вклад.

Это соответствует ожиданиям: в синтетическом датасете информативность заложена в `num*`-переменных, а `cat*` служат фоновыми факторами.

---

## 6. Conclusion

1. **Деревья легко переобучаются**, но контроль сложности (`max_depth`, `min_samples_leaf`) эффективно снижает дисперсию.
2. **Random Forest** - мощный и устойчивый ансамбль, который значительно превосходит одиночное дерево за счёт bagging и случайности по признакам.
3. **Boosting (AdaBoost)** работает хуже Random Forest на этом датасете, возможно, из-за чувствительности к шуму или недостаточной глубины базовых моделей.
4. **Честный ML-протокол** (фиксированный train/test, CV на train, оценка на test один раз) критически важен для объективного сравнения моделей.
5. **Permutation importance** - надёжный способ интерпретации, особенно для ансамблей, где встроенная `feature_importances_` может быть смещена.
6. **Baseline’ы (Dummy, LogReg)** необходимы: без них легко ошибиться, приняв слабую модель за хорошую.